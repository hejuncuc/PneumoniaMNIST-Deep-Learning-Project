{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:27.810093Z",
     "start_time": "2022-04-22T05:10:26.624545Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from numpy.random import RandomState\n",
    "from torch.utils.data import Subset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:27.859781Z",
     "start_time": "2022-04-22T05:10:27.811785Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if display:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, name=\"\\nVal\"):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.binary_cross_entropy_with_logits(\n",
    "                output, target.float(), size_average=False).item()  # sum up batch loss\n",
    "            pred = output >= 0.5\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:27.866041Z",
     "start_time": "2022-04-22T05:10:27.861213Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.layers += [nn.Conv2d(1, 16,  kernel_size=3),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "        self.layers += [nn.Conv2d(16, 16,  kernel_size=3, stride=2),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "        self.layers += [nn.Conv2d(16, 32,  kernel_size=3),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "        self.layers += [nn.Conv2d(32, 32,  kernel_size=3, stride=2),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "        self.fc = nn.Linear(32*4*4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)):\n",
    "            x = self.layers[i](x)\n",
    "        x = x.view(-1, 32*4*4)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:28.017892Z",
     "start_time": "2022-04-22T05:10:27.867941Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTConfig, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:28.022757Z",
     "start_time": "2022-04-22T05:10:28.019421Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# preprocessing\n",
    "data_flag = 'pneumoniamnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "n_classes = len(info['label'])\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:28.026506Z",
     "start_time": "2022-04-22T05:10:28.023902Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "      transforms.Resize(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[.5], std=[.5]),\n",
    "      transforms.Lambda(lambda x: x.repeat(3, 1, 1) )\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T05:10:43.827810Z",
     "start_time": "2022-04-22T05:10:28.027928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/z_yuxian/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/z_yuxian/.medmnist/pneumoniamnist.npz\n",
      "Num Samples For Training 10 Num Samples For Val 1000\n",
      "Train Epoch: 0 [0/10 (0%)]\tLoss: 0.710226\n",
      "Train Epoch: 5 [0/10 (0%)]\tLoss: 0.307619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z_yuxian/miniconda3/envs/nn/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.3712, Accuracy: 879/1000 (87.90%)\n",
      "\n",
      "Num Samples For Training 10 Num Samples For Val 1000\n",
      "Train Epoch: 0 [0/10 (0%)]\tLoss: 0.710544\n",
      "Train Epoch: 5 [0/10 (0%)]\tLoss: 0.373800\n",
      "\n",
      "Val set: Average loss: 0.4339, Accuracy: 869/1000 (86.90%)\n",
      "\n",
      "Num Samples For Training 10 Num Samples For Val 1000\n",
      "Train Epoch: 0 [0/10 (0%)]\tLoss: 0.702258\n",
      "Train Epoch: 5 [0/10 (0%)]\tLoss: 0.287211\n",
      "\n",
      "Val set: Average loss: 0.3748, Accuracy: 873/1000 (87.30%)\n",
      "\n",
      "Val acc over 5 instances on dataset: pneumoniamnist 87.37 +- 0.41\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "val_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "\n",
    "accs_val = []\n",
    "\n",
    "for seed in  range(0, 3):\n",
    "  prng = RandomState(seed)\n",
    "  random_permute = prng.permutation(np.arange(0, 1000))\n",
    "  train_top = 10//n_classes\n",
    "  val_top = 1000//n_classes\n",
    "  indx_train = np.concatenate([np.where(train_dataset.labels == label)[0][random_permute[0:train_top]] for label in range(0, n_classes)])\n",
    "  indx_val = np.concatenate([np.where(train_dataset.labels == label)[0][random_permute[train_top:train_top + val_top]] for label in range(0, n_classes)])\n",
    "\n",
    "  train_data = Subset(train_dataset, indx_train)\n",
    "  val_data = Subset(val_dataset, indx_val)\n",
    "\n",
    "  print('Num Samples For Training %d Num Samples For Val %d'%(train_data.indices.shape[0],val_data.indices.shape[0]))\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size=32, \n",
    "                                             shuffle=True)\n",
    "\n",
    "  val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                             batch_size=128, \n",
    "                                             shuffle=False)\n",
    "  model = models.vgg16(pretrained=True)\n",
    "  model.classifier = nn.Linear(512 * 7 * 7, 1)\n",
    "\n",
    "  model.to(device).train() \n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # Observe that all parameters are being optimized\n",
    "#   optimizer = optim.Adam(model.classifier.parameters(),lr=1e-3)\n",
    "  optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "  for epoch in range(10):\n",
    "    train(model, device, train_loader, optimizer, epoch, display=epoch%5==0)\n",
    "  accs_val.append(test(model, device, val_loader))\n",
    "\n",
    "accs_val = np.array(accs_val)\n",
    "\n",
    "print('Val acc over 5 instances on dataset: %s %.2f +- %.2f'%(data_flag, accs_val.mean(), accs_val.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
