{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 7400,
     "status": "ok",
     "timestamp": 1650663918459,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "nQtrGLxbEsFK"
   },
   "source": [
    "!pip install -qqq transformers medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:24:59.135911Z",
     "start_time": "2022-04-25T05:24:57.307043Z"
    },
    "executionInfo": {
     "elapsed": 2832,
     "status": "ok",
     "timestamp": 1650663921289,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "eX-HlT4oEm4l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from numpy.random import RandomState\n",
    "from torch.utils.data import Subset\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:24:59.143938Z",
     "start_time": "2022-04-25T05:24:59.137495Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650663921290,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "X8k8euFOEm4o"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(torch.float32).to(device), target.to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, labels=target)\n",
    "        loss = output.loss # F.binary_cross_entropy_with_logits(output.logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if display:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, name=\"\\nVal\", get_loss=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(torch.float32).to(device)\n",
    "            output = model(data, labels=target)\n",
    "            test_loss += output.loss.item() # F.binary_cross_entropy_with_logits(output.logits, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.logits > 0.5\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if get_loss:\n",
    "        return test_loss\n",
    "    print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:24:59.345035Z",
     "start_time": "2022-04-25T05:24:59.145466Z"
    },
    "executionInfo": {
     "elapsed": 5031,
     "status": "ok",
     "timestamp": 1650663926319,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "c15_SxabEm4p"
   },
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, ViTConfig, ViTFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:24:59.350778Z",
     "start_time": "2022-04-25T05:24:59.347087Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650663926319,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "QE3YZNLCEm4p"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# preprocessing\n",
    "data_flag = 'pneumoniamnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "n_classes = len(info['label'])\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:24:59.524118Z",
     "start_time": "2022-04-25T05:24:59.352384Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1650663926320,
     "user": {
      "displayName": "Yu Xiang Zhang",
      "userId": "12790163513299645393"
     },
     "user_tz": 240
    },
    "id": "AxSc_H3eEm4q"
   },
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "grayToRgb = transforms.Lambda(lambda x: x.repeat(3, 1, 1) )\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandAugment(),\n",
    "            transforms.RandomResizedCrop(feature_extractor.size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            grayToRgb\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(feature_extractor.size),\n",
    "            transforms.CenterCrop(feature_extractor.size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            grayToRgb\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "      transforms.Resize(224),\n",
    "      transforms.ToTensor(),\n",
    "      normalize,\n",
    "      grayToRgb\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T05:26:08.407298Z",
     "start_time": "2022-04-25T05:24:59.525547Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aICSX6bbEm4q",
    "outputId": "b12e018e-f561-4460-e4d7-b0d1f077e4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/z_yuxian/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/z_yuxian/.medmnist/pneumoniamnist.npz\n",
      "Num Samples For Training 10 Num Samples For Val 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/10 (0%)]\tLoss: 0.400647\n",
      "Train Epoch: 5 [0/10 (0%)]\tLoss: 0.272314\n",
      "Train Epoch: 10 [0/10 (0%)]\tLoss: 0.221450\n",
      "Train Epoch: 15 [0/10 (0%)]\tLoss: 0.221607\n",
      "Train Epoch: 20 [0/10 (0%)]\tLoss: 0.173997\n",
      "Train Epoch: 25 [0/10 (0%)]\tLoss: 0.144859\n",
      "Train Epoch: 30 [0/10 (0%)]\tLoss: 0.130422\n",
      "Train Epoch: 35 [0/10 (0%)]\tLoss: 0.108831\n",
      "Train Epoch: 40 [0/10 (0%)]\tLoss: 0.092914\n",
      "Train Epoch: 45 [0/10 (0%)]\tLoss: 0.082106\n",
      "Train Epoch: 50 [0/10 (0%)]\tLoss: 0.071344\n",
      "Train Epoch: 55 [0/10 (0%)]\tLoss: 0.062784\n",
      "Train Epoch: 60 [0/10 (0%)]\tLoss: 0.056112\n",
      "Train Epoch: 65 [0/10 (0%)]\tLoss: 0.050074\n",
      "Train Epoch: 70 [0/10 (0%)]\tLoss: 0.044991\n",
      "Train Epoch: 75 [0/10 (0%)]\tLoss: 0.040764\n",
      "Train Epoch: 80 [0/10 (0%)]\tLoss: 0.037042\n",
      "Train Epoch: 85 [0/10 (0%)]\tLoss: 0.033813\n",
      "Train Epoch: 90 [0/10 (0%)]\tLoss: 0.031004\n",
      "Train Epoch: 95 [0/10 (0%)]\tLoss: 0.028492\n",
      "Train Epoch: 100 [0/10 (0%)]\tLoss: 0.026257\n",
      "Train Epoch: 105 [0/10 (0%)]\tLoss: 0.024264\n",
      "Train Epoch: 110 [0/10 (0%)]\tLoss: 0.022476\n",
      "Train Epoch: 115 [0/10 (0%)]\tLoss: 0.020863\n",
      "Train Epoch: 120 [0/10 (0%)]\tLoss: 0.019402\n",
      "Train Epoch: 125 [0/10 (0%)]\tLoss: 0.018075\n",
      "Train Epoch: 130 [0/10 (0%)]\tLoss: 0.016863\n",
      "Train Epoch: 135 [0/10 (0%)]\tLoss: 0.015756\n",
      "Train Epoch: 140 [0/10 (0%)]\tLoss: 0.014748\n",
      "Train Epoch: 145 [0/10 (0%)]\tLoss: 0.013822\n",
      "Train Epoch: 150 [0/10 (0%)]\tLoss: 0.012974\n",
      "Train Epoch: 155 [0/10 (0%)]\tLoss: 0.012192\n",
      "Train Epoch: 160 [0/10 (0%)]\tLoss: 0.011474\n",
      "Train Epoch: 165 [0/10 (0%)]\tLoss: 0.010813\n",
      "Train Epoch: 170 [0/10 (0%)]\tLoss: 0.010200\n",
      "Train Epoch: 175 [0/10 (0%)]\tLoss: 0.009636\n",
      "Train Epoch: 180 [0/10 (0%)]\tLoss: 0.009115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#     scheduler.step()\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep(\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     52\u001b[0m   accs_val\u001b[38;5;241m.\u001b[39mappend(test(model, device, val_loader))\n\u001b[1;32m     54\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(losses_train, label\u001b[38;5;241m=\u001b[39mseed)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, name, get_loss)\u001b[0m\n\u001b[1;32m     25\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data, labels\u001b[38;5;241m=\u001b[39mtarget)\n\u001b[0;32m---> 27\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# F.binary_cross_entropy_with_logits(output.logits, target, reduction='sum').item()  # sum up batch loss\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     29\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target\u001b[38;5;241m.\u001b[39mview_as(pred))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transforms, download=download)\n",
    "val_dataset = DataClass(split='train', transform=data_transforms, download=download)\n",
    "\n",
    "accs_val = []\n",
    "\n",
    "for seed in  range(1, 51):\n",
    "  prng = RandomState(seed)\n",
    "  random_permute = prng.permutation(np.arange(0, 1000))\n",
    "  train_top = 10//n_classes\n",
    "  val_top = 1000//n_classes\n",
    "  indx_train = np.concatenate([np.where(train_dataset.labels == label)[0][random_permute[0:train_top]] for label in range(0, n_classes)])\n",
    "  indx_val = np.concatenate([np.where(train_dataset.labels == label)[0][random_permute[train_top:train_top + val_top]] for label in range(0, n_classes)])\n",
    "\n",
    "  train_data = Subset(train_dataset, indx_train)\n",
    "  val_data = Subset(val_dataset, indx_val)\n",
    "\n",
    "  print('Num Samples For Training %d Num Samples For Val %d'%(train_data.indices.shape[0],val_data.indices.shape[0]))\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size=32, \n",
    "                                             shuffle=True)\n",
    "\n",
    "  val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                             batch_size=128, \n",
    "                                             shuffle=False)\n",
    "#   model = models.alexnet(pretrained=True)\n",
    "#   model.classifier = nn.Linear(256 * 6 * 6, 1)\n",
    "\n",
    "  # Initializing a model from the vit-base-patch16-224 style configuration\n",
    "  model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=1\n",
    "  )\n",
    "  model.to(device).train() \n",
    "#   optimizer = optim.Adam(model.classifier.parameters(),lr=1e-3, weight_decay=0.005)\n",
    "#   optimizer = optim.AdamW(model.classifier.parameters(), lr=1e-3)\n",
    "  optimizer = optim.SGD(model.classifier.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.1)\n",
    "  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#   scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.99)\n",
    "  losses_train = []\n",
    "  for epoch in range(200):\n",
    "    train_loss = train(model, device, train_loader, optimizer, epoch, display=epoch%5==0)\n",
    "    losses_train.append(train_loss)\n",
    "#     scheduler.step()\n",
    "    if epoch%10 == 0:\n",
    "        scheduler.step(test(model, device, val_loader, get_loss=True))\n",
    "\n",
    "  accs_val.append(test(model, device, val_loader))\n",
    "\n",
    "  plt.plot(losses_train, label=seed)\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('loss')\n",
    "  plt.title(f'Training loss over 1000 epochs for ViT with binary_cross_entropy_with_logits')\n",
    "  plt.legend()\n",
    "  plt.savefig(f'img/vit_converge_seed{seed}.png')\n",
    "\n",
    "accs_val = np.array(accs_val)\n",
    "\n",
    "print('Val acc over %d instances on dataset: %s %.2f +- %.2f'%(len(accs_val), data_flag, accs_val.mean(), accs_val.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ViTForImageClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "323.458px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
